{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-26T15:33:32.225808Z",
     "start_time": "2025-04-26T15:33:32.208585Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "from pathlib import Path"
   ],
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset",
   "id": "f5219fb06b991d19"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T15:33:32.246262Z",
     "start_time": "2025-04-26T15:33:32.225808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ColorizationDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.gray_paths = list((self.root_dir / \"gray\").glob(\"*\"))\n",
    "        self.color_paths = list((self.root_dir / \"color\").glob(\"*\"))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gray_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        gray_path = self.gray_paths[idx]\n",
    "        color_path = self.color_paths[idx]\n",
    "\n",
    "        gray_image = Image.open(gray_path).convert(\"L\")  # 1-Kanal\n",
    "        color_image = Image.open(color_path).convert(\"RGB\")  # 3-Kanal\n",
    "\n",
    "        if self.transform:\n",
    "            gray_image = self.transform(gray_image)\n",
    "            color_image = self.transform(color_image)\n",
    "\n",
    "        # Graubild zu 3 Kanälen duplizieren\n",
    "        gray_image = gray_image.expand(3, -1, -1)\n",
    "\n",
    "        # Zusätzlich den Dateinamen zurückgeben\n",
    "        filename = gray_path.stem  # Nur der Name ohne \".jpg\" oder \".png\"\n",
    "\n",
    "        return gray_image, color_image, filename"
   ],
   "id": "a6c18905f5d9159c",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Generater",
   "id": "d6c41d994d657816"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T15:33:32.296733Z",
     "start_time": "2025-04-26T15:33:32.288086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class UNetGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNetGenerator, self).__init__()\n",
    "\n",
    "        def down_block(in_channels, out_channels):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 4, 2, 1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.LeakyReLU(0.2)\n",
    "            )\n",
    "\n",
    "        def up_block(in_channels, out_channels):\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "\n",
    "        self.down1 = down_block(3, 64)\n",
    "        self.down2 = down_block(64, 128)\n",
    "        self.down3 = down_block(128, 256)\n",
    "        self.down4 = down_block(256, 512)\n",
    "\n",
    "        self.up1 = up_block(512, 256)\n",
    "        self.up2 = up_block(512, 128)\n",
    "        self.up3 = up_block(256, 64)\n",
    "        self.up4 = nn.ConvTranspose2d(128, 3, 4, 2, 1)  # Output RGB\n",
    "\n",
    "    def forward(self, x):\n",
    "        d1 = self.down1(x)\n",
    "        d2 = self.down2(d1)\n",
    "        d3 = self.down3(d2)\n",
    "        d4 = self.down4(d3)\n",
    "\n",
    "        u1 = self.up1(d4)\n",
    "        u1 = torch.cat([u1, d3], dim=1)\n",
    "        u2 = self.up2(u1)\n",
    "        u2 = torch.cat([u2, d2], dim=1)\n",
    "        u3 = self.up3(u2)\n",
    "        u3 = torch.cat([u3, d1], dim=1)\n",
    "        output = torch.tanh(self.up4(u3))\n",
    "        return output"
   ],
   "id": "c8b8dfffa14552d6",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Discriminator",
   "id": "2e3430c0dcb8569e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T15:33:32.344105Z",
     "start_time": "2025-04-26T15:33:32.338137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(6, 64, 4, 2, 1),  # (gray + color)\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(256, 1, 4, 1, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, gray, color):\n",
    "        x = torch.cat([gray, color], dim=1)\n",
    "        return self.model(x)"
   ],
   "id": "cb9199f8c671166c",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T15:33:32.390338Z",
     "start_time": "2025-04-26T15:33:32.384438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hyperparameter\n",
    "lr_generator = 2e-4\n",
    "lr_discriminator = 1e-4\n",
    "b1_generator = 0.5\n",
    "b2_generator = 0.999\n",
    "b1_discriminator = 0.5\n",
    "b2_discriminator = 0.999\n",
    "epochs = 100\n",
    "batch_size = 8\n",
    "datapath = Path.cwd() / \"images\"\n",
    "output_folder = Path.cwd() / \"images\" / \"generated\""
   ],
   "id": "b754a68c950abde9",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T15:34:06.893213Z",
     "start_time": "2025-04-26T15:33:32.431783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Modelle\n",
    "gen = UNetGenerator().to(device)\n",
    "disc = Discriminator().to(device)\n",
    "\n",
    "# Optimizer\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr_generator, betas=(b1_generator, b2_generator))\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=lr_discriminator, betas=(b1_discriminator, b2_discriminator))\n",
    "\n",
    "# Loss Funktionen\n",
    "criterion_GAN = nn.BCELoss()\n",
    "criterion_L1 = nn.L1Loss()\n",
    "\n",
    "# DataLoader\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = ColorizationDataset(datapath, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training\n",
    "for epoch in range(epochs):\n",
    "    for idx, (gray, color, filename) in enumerate(dataloader):\n",
    "        gray = gray.to(device)\n",
    "        color = color.to(device)\n",
    "\n",
    "        fake_color = gen(gray)\n",
    "        real_pair = disc(gray, color)\n",
    "        fake_pair = disc(gray, fake_color.detach())\n",
    "\n",
    "        real_labels = torch.ones_like(real_pair)\n",
    "        fake_labels = torch.zeros_like(fake_pair)\n",
    "\n",
    "        loss_real = criterion_GAN(real_pair, real_labels)\n",
    "        loss_fake = criterion_GAN(fake_pair, fake_labels)\n",
    "        loss_disc = (loss_real + loss_fake) / 2\n",
    "\n",
    "        opt_disc.zero_grad()\n",
    "        loss_disc.backward()\n",
    "        opt_disc.step()\n",
    "\n",
    "        # ==================== Generator ====================\n",
    "        fake_pair = disc(gray, fake_color)\n",
    "        loss_gan = criterion_GAN(fake_pair, real_labels)\n",
    "        loss_l1 = criterion_L1(fake_color, color) * 100\n",
    "\n",
    "        loss_gen = loss_gan + loss_l1\n",
    "\n",
    "        opt_gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        if idx % 100 == 0:\n",
    "            print(f\"Epoch [{epoch}/{epochs}] Batch [{idx}/{len(dataloader)}] \"\n",
    "                  f\"Loss D: {loss_disc.item():.4f}, loss G: {loss_gen.item():.4f}\")\n",
    "\n",
    "    # --> Am Ende jedes Epochs: speichere das aktuelle fake_color\n",
    "    # Aber Achtung: Hier nehmen wir NUR das erste Bild im Batch [0]\n",
    "    save_path = output_folder / f\"{filename[0]}_generated.png\"\n",
    "    save_image(fake_color[0], save_path)  # [0] weil Batch\n",
    "\n",
    "print(\"✅ Training abgeschlossen!\")"
   ],
   "id": "64393187c9952cfd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100] Batch [0/1] Loss D: 0.7137, loss G: 58.4400\n",
      "Epoch [1/100] Batch [0/1] Loss D: 0.6836, loss G: 50.3474\n",
      "Epoch [2/100] Batch [0/1] Loss D: 0.6570, loss G: 44.2196\n",
      "Epoch [3/100] Batch [0/1] Loss D: 0.6336, loss G: 39.6873\n",
      "Epoch [4/100] Batch [0/1] Loss D: 0.6113, loss G: 36.2992\n",
      "Epoch [5/100] Batch [0/1] Loss D: 0.5932, loss G: 34.6737\n",
      "Epoch [6/100] Batch [0/1] Loss D: 0.5702, loss G: 32.2293\n",
      "Epoch [7/100] Batch [0/1] Loss D: 0.5522, loss G: 30.2861\n",
      "Epoch [8/100] Batch [0/1] Loss D: 0.5314, loss G: 28.9496\n",
      "Epoch [9/100] Batch [0/1] Loss D: 0.5097, loss G: 27.8018\n",
      "Epoch [10/100] Batch [0/1] Loss D: 0.4928, loss G: 26.6776\n",
      "Epoch [11/100] Batch [0/1] Loss D: 0.4777, loss G: 25.9010\n",
      "Epoch [12/100] Batch [0/1] Loss D: 0.4534, loss G: 25.6020\n",
      "Epoch [13/100] Batch [0/1] Loss D: 0.4346, loss G: 25.3500\n",
      "Epoch [14/100] Batch [0/1] Loss D: 0.4127, loss G: 24.2883\n",
      "Epoch [15/100] Batch [0/1] Loss D: 0.4020, loss G: 23.3772\n",
      "Epoch [16/100] Batch [0/1] Loss D: 0.3789, loss G: 22.9699\n",
      "Epoch [17/100] Batch [0/1] Loss D: 0.3569, loss G: 22.2688\n",
      "Epoch [18/100] Batch [0/1] Loss D: 0.3395, loss G: 21.5906\n",
      "Epoch [19/100] Batch [0/1] Loss D: 0.3217, loss G: 21.0734\n",
      "Epoch [20/100] Batch [0/1] Loss D: 0.3109, loss G: 20.9370\n",
      "Epoch [21/100] Batch [0/1] Loss D: 0.2963, loss G: 20.7097\n",
      "Epoch [22/100] Batch [0/1] Loss D: 0.2937, loss G: 20.6460\n",
      "Epoch [23/100] Batch [0/1] Loss D: 0.2730, loss G: 19.8678\n",
      "Epoch [24/100] Batch [0/1] Loss D: 0.2589, loss G: 19.3302\n",
      "Epoch [25/100] Batch [0/1] Loss D: 0.2445, loss G: 19.0519\n",
      "Epoch [26/100] Batch [0/1] Loss D: 0.2337, loss G: 18.5932\n",
      "Epoch [27/100] Batch [0/1] Loss D: 0.2246, loss G: 18.2518\n",
      "Epoch [28/100] Batch [0/1] Loss D: 0.2122, loss G: 18.2461\n",
      "Epoch [29/100] Batch [0/1] Loss D: 0.2081, loss G: 18.0953\n",
      "Epoch [30/100] Batch [0/1] Loss D: 0.2006, loss G: 18.4640\n",
      "Epoch [31/100] Batch [0/1] Loss D: 0.1953, loss G: 17.7631\n",
      "Epoch [32/100] Batch [0/1] Loss D: 0.1901, loss G: 17.2059\n",
      "Epoch [33/100] Batch [0/1] Loss D: 0.1907, loss G: 16.7135\n",
      "Epoch [34/100] Batch [0/1] Loss D: 0.1931, loss G: 16.6121\n",
      "Epoch [35/100] Batch [0/1] Loss D: 0.1951, loss G: 16.6397\n",
      "Epoch [36/100] Batch [0/1] Loss D: 0.1727, loss G: 16.6230\n",
      "Epoch [37/100] Batch [0/1] Loss D: 0.1742, loss G: 15.9558\n",
      "Epoch [38/100] Batch [0/1] Loss D: 0.1694, loss G: 15.7593\n",
      "Epoch [39/100] Batch [0/1] Loss D: 0.1676, loss G: 15.5151\n",
      "Epoch [40/100] Batch [0/1] Loss D: 0.1724, loss G: 15.6040\n",
      "Epoch [41/100] Batch [0/1] Loss D: 0.1807, loss G: 15.2053\n",
      "Epoch [42/100] Batch [0/1] Loss D: 0.1794, loss G: 15.0071\n",
      "Epoch [43/100] Batch [0/1] Loss D: 0.1805, loss G: 14.7902\n",
      "Epoch [44/100] Batch [0/1] Loss D: 0.1958, loss G: 14.7570\n",
      "Epoch [45/100] Batch [0/1] Loss D: 0.1973, loss G: 14.4560\n",
      "Epoch [46/100] Batch [0/1] Loss D: 0.2166, loss G: 14.1411\n",
      "Epoch [47/100] Batch [0/1] Loss D: 0.1960, loss G: 14.1473\n",
      "Epoch [48/100] Batch [0/1] Loss D: 0.2011, loss G: 13.4665\n",
      "Epoch [49/100] Batch [0/1] Loss D: 0.2081, loss G: 13.5143\n",
      "Epoch [50/100] Batch [0/1] Loss D: 0.1957, loss G: 13.6745\n",
      "Epoch [51/100] Batch [0/1] Loss D: 0.2035, loss G: 13.7411\n",
      "Epoch [52/100] Batch [0/1] Loss D: 0.1845, loss G: 13.1585\n",
      "Epoch [53/100] Batch [0/1] Loss D: 0.1842, loss G: 12.8983\n",
      "Epoch [54/100] Batch [0/1] Loss D: 0.1683, loss G: 13.1734\n",
      "Epoch [55/100] Batch [0/1] Loss D: 0.1836, loss G: 13.0549\n",
      "Epoch [56/100] Batch [0/1] Loss D: 0.1740, loss G: 13.0807\n",
      "Epoch [57/100] Batch [0/1] Loss D: 0.1779, loss G: 12.9035\n",
      "Epoch [58/100] Batch [0/1] Loss D: 0.1828, loss G: 13.3263\n",
      "Epoch [59/100] Batch [0/1] Loss D: 0.1573, loss G: 13.5587\n",
      "Epoch [60/100] Batch [0/1] Loss D: 0.1608, loss G: 12.3872\n",
      "Epoch [61/100] Batch [0/1] Loss D: 0.1859, loss G: 12.3223\n",
      "Epoch [62/100] Batch [0/1] Loss D: 0.1605, loss G: 12.0471\n",
      "Epoch [63/100] Batch [0/1] Loss D: 0.1779, loss G: 12.1878\n",
      "Epoch [64/100] Batch [0/1] Loss D: 0.1597, loss G: 12.1731\n",
      "Epoch [65/100] Batch [0/1] Loss D: 0.1866, loss G: 12.0428\n",
      "Epoch [66/100] Batch [0/1] Loss D: 0.1950, loss G: 11.5240\n",
      "Epoch [67/100] Batch [0/1] Loss D: 0.1684, loss G: 11.5019\n",
      "Epoch [68/100] Batch [0/1] Loss D: 0.1833, loss G: 11.6650\n",
      "Epoch [69/100] Batch [0/1] Loss D: 0.1853, loss G: 11.5198\n",
      "Epoch [70/100] Batch [0/1] Loss D: 0.1550, loss G: 11.6807\n",
      "Epoch [71/100] Batch [0/1] Loss D: 0.2077, loss G: 11.8377\n",
      "Epoch [72/100] Batch [0/1] Loss D: 0.1942, loss G: 11.4985\n",
      "Epoch [73/100] Batch [0/1] Loss D: 0.1607, loss G: 10.9412\n",
      "Epoch [74/100] Batch [0/1] Loss D: 0.1735, loss G: 10.7957\n",
      "Epoch [75/100] Batch [0/1] Loss D: 0.1602, loss G: 11.0591\n",
      "Epoch [76/100] Batch [0/1] Loss D: 0.1736, loss G: 10.8667\n",
      "Epoch [77/100] Batch [0/1] Loss D: 0.1791, loss G: 10.7819\n",
      "Epoch [78/100] Batch [0/1] Loss D: 0.1721, loss G: 10.3546\n",
      "Epoch [79/100] Batch [0/1] Loss D: 0.1965, loss G: 10.6959\n",
      "Epoch [80/100] Batch [0/1] Loss D: 0.1594, loss G: 10.8027\n",
      "Epoch [81/100] Batch [0/1] Loss D: 0.1959, loss G: 10.1650\n",
      "Epoch [82/100] Batch [0/1] Loss D: 0.1981, loss G: 10.1827\n",
      "Epoch [83/100] Batch [0/1] Loss D: 0.1892, loss G: 10.3692\n",
      "Epoch [84/100] Batch [0/1] Loss D: 0.2216, loss G: 10.1691\n",
      "Epoch [85/100] Batch [0/1] Loss D: 0.2130, loss G: 10.0899\n",
      "Epoch [86/100] Batch [0/1] Loss D: 0.2262, loss G: 9.5636\n",
      "Epoch [87/100] Batch [0/1] Loss D: 0.3197, loss G: 9.4897\n",
      "Epoch [88/100] Batch [0/1] Loss D: 0.2688, loss G: 10.0977\n",
      "Epoch [89/100] Batch [0/1] Loss D: 0.2885, loss G: 10.5848\n",
      "Epoch [90/100] Batch [0/1] Loss D: 0.3510, loss G: 9.1417\n",
      "Epoch [91/100] Batch [0/1] Loss D: 0.3229, loss G: 9.5483\n",
      "Epoch [92/100] Batch [0/1] Loss D: 0.2472, loss G: 9.5984\n",
      "Epoch [93/100] Batch [0/1] Loss D: 0.2228, loss G: 9.2221\n",
      "Epoch [94/100] Batch [0/1] Loss D: 0.1734, loss G: 9.7710\n",
      "Epoch [95/100] Batch [0/1] Loss D: 0.1819, loss G: 9.4368\n",
      "Epoch [96/100] Batch [0/1] Loss D: 0.1810, loss G: 9.6456\n",
      "Epoch [97/100] Batch [0/1] Loss D: 0.1661, loss G: 9.4586\n",
      "Epoch [98/100] Batch [0/1] Loss D: 0.1373, loss G: 10.2456\n",
      "Epoch [99/100] Batch [0/1] Loss D: 0.1896, loss G: 9.0719\n",
      "✅ Training abgeschlossen!\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-26T15:34:06.963890Z",
     "start_time": "2025-04-26T15:34:06.958352Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "720bafab1995d9df",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (colorizer-env)",
   "language": "python",
   "name": "colorizer-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
